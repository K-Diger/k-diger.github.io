---

title: 쿠버네티스 코어 오브젝트 (Pods, ReplicaSets, Deployments, StatefulSets, Services, Ingress, ConfigMaps, Secrets, PVC, Jobs, DaemonSets)
date: 2025-08-17
categories: [K8s, Pods, ReplicaSets, Deployments, StatefulSets, Services, Ingress, ConfigMaps, Secrets, PVC, Jobs, DaemonSets]
tags: [K8s, Pods, ReplicaSets, Deployments, StatefulSets, Services, Ingress, ConfigMaps, Secrets, PVC, Jobs, DaemonSets]
layout: post
toc: true
math: true
mermaid: true

---

# 쿠버네티스 Core Objects

쿠버네티스의 Core Objects는 애플리케이션을 배포하고 관리하는 기본 단위다.

## 1. Pods: 쿠버네티스의 최소 실행 단위

### 1.1 Pod의 내부 구조

Pod는 단순히 "컨테이너를 감싸는 래퍼"가 아니다. 공유 네트워킹과 스토리지를 가진 독립적인 실행 환경이다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-container-pod
  labels:
    app: example
spec:
  containers:
    - name: web-server
      image: nginx:1.21
      ports:
        - containerPort: 80
      volumeMounts:
        - name: shared-data
          mountPath: /usr/share/nginx/html
    - name: content-updater
      image: busybox
      command: [ 'sh', '-c' ]
      args:
        - while true; do
          echo "$(date): Hello from sidecar" > /shared/index.html;
          sleep 30;
          done
      volumeMounts:
        - name: shared-data
          mountPath: /shared
  volumes:
    - name: shared-data
      emptyDir: { }
```

**Pod 내부의 네트워킹:**

- 모든 컨테이너는 동일한 IP 주소 공유
- localhost를 통한 컨테이너 간 통신
- 포트 충돌 방지 필요

### 1.2 Pod 생명주기와 상태 관리

```
┌─────────────────────────────────────────────────────────────┐
│                    Pod Lifecycle                            │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Pending → Running → Succeeded/Failed                       │
│     │         │           │                                 │
│     ▼         ▼           ▼                                 │
│  ┌─────┐  ┌─────┐     ┌─────────┐                           │
│  │스케줄│  │컨테이│      │파드 완료│                              │
│  │링 중│  │너실행│      │또는실패│                               │
│  └─────┘  └─────┘     └─────────┘                           │
│                                                             │
│  PodConditions:                                             │
│  • PodScheduled: 노드에 스케줄링 완료                            │
│  • Initialized: 모든 Init 컨테이너 완료                         │
│  • ContainersReady: 모든 컨테이너 준비 완료                       │
│  • Ready: Pod이 트래픽 수신 준비 완료                             │
└─────────────────────────────────────────────────────────────┘
```

### 1.3 고급 Pod 설정

**Init Containers:**

```yaml
spec:
  initContainers:
    - name: db-migration
      image: migrate/migrate
      command: [ 'migrate', '-path', '/migrations', '-database', 'postgres://...', 'up' ]
    - name: config-setup
      image: busybox
      command: [ 'sh', '-c', 'cp /config-template/* /config/' ]
      volumeMounts:
        - name: config-volume
          mountPath: /config
```

**Security Context:**

```yaml
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
    seccompProfile:
      type: RuntimeDefault
  containers:
    - name: app
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        capabilities:
          drop:
            - ALL
          add:
            - NET_BIND_SERVICE
```

## 2. ReplicaSets: 파드 복제본 관리

### 2.1 ReplicaSet의 동작 원리

ReplicaSet은 Control Loop 패턴을 사용해 원하는 수의 파드 복제본을 유지한다.

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-replicaset
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
    matchExpressions:
      - key: tier
        operator: In
        values: [ "frontend" ]
  template:
    metadata:
      labels:
        app: nginx
        tier: frontend
    spec:
      containers:
        - name: nginx
          image: nginx:1.21
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 200m
              memory: 256Mi
```

### 2.2 ReplicaSet Controller의 Reconciliation 과정

```
┌─────────────────────────────────────────────────────────────┐
│               ReplicaSet Reconciliation                     │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  1. 현재 상태 확인                                         │
│     ├── 실행 중인 파드 수 계산                             │
│     ├── 라벨 셀렉터로 파드 필터링                          │
│     └── 파드 상태 검증 (Running, Pending, Failed)         │
│                                                             │
│  2. 원하는 상태와 비교                                     │
│     ├── Desired Replicas: 3                                │
│     ├── Current Replicas: 2                                │
│     └── Diff: +1 (파드 1개 추가 필요)                     │
│                                                             │
│  3. 조정 작업 수행                                         │
│     ├── 부족한 경우: 새 파드 생성                          │
│     ├── 초과한 경우: 가장 오래된 파드 삭제                 │
│     └── 실패한 파드: 새로운 파드로 교체                    │
│                                                             │
│  4. 상태 업데이트                                          │
│     ├── ReplicaSet Status 업데이트                         │
│     ├── 이벤트 생성 및 로그 기록                           │
│     └── 다음 Reconciliation 주기 대기                     │
└─────────────────────────────────────────────────────────────┘
```

## 3. Deployments: 선언적 업데이트 관리

### 3.1 Deployment의 계층 구조

```
Deployment
    ↓ (관리)
ReplicaSet (v1)     ReplicaSet (v2)
    ↓                    ↓
Pod Pod Pod         Pod Pod Pod
```

### 3.2 롤링 업데이트 전략

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1      # 동시에 중단 가능한 파드 수
      maxSurge: 2           # 동시에 추가 생성 가능한 파드 수
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:1.21
          readinessProbe:
            httpGet:
              path: /
              port: 80
            initialDelaySeconds: 5
            periodSeconds: 5
```

### 3.3 롤링 업데이트 과정 상세

```
┌─────────────────────────────────────────────────────────────┐
│                 Rolling Update Process                      │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  초기 상태: nginx:1.20 (5개 파드)                         │
│  ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐                 │
│  │ v20 │ │ v20 │ │ v20 │ │ v20 │ │ v20 │                 │
│  └─────┘ └─────┘ └─────┘ └─────┘ └─────┘                 │
│                                                             │
│  1단계: 새 ReplicaSet 생성 및 파드 2개 추가 (maxSurge=2)  │
│  ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ │
│  │ v20 │ │ v20 │ │ v20 │ │ v20 │ │ v20 │ │ v21 │ │ v21 │ │
│  └─────┘ └─────┘ └─────┘ └─────┘ └─────┘ └─────┘ └─────┘ │
│                                                             │
│  2단계: 새 파드 Ready 확인 후 기존 파드 1개 제거          │
│  ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐         │
│  │ v20 │ │ v20 │ │ v20 │ │ v20 │ │ v21 │ │ v21 │         │
│  └─────┘ └─────┘ └─────┘ └─────┘ └─────┘ └─────┘         │
│                                                             │
│  3단계: 과정 반복하여 모든 파드 교체 완료                 │
│  ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐                 │
│  │ v21 │ │ v21 │ │ v21 │ │ v21 │ │ v21 │                 │
│  └─────┘ └─────┘ └─────┘ └─────┘ └─────┘                 │
└─────────────────────────────────────────────────────────────┘
```

### 3.4 고급 Deployment 기능

**Blue-Green 배포 시뮬레이션:**

```yaml
strategy:
  type: Recreate  # 모든 파드를 한 번에 교체
```

**Canary 배포:**

```bash
# 일부 트래픽만 새 버전으로 라우팅
kubectl patch deployment nginx-deployment -p '{"spec":{"replicas":10}}'
kubectl set image deployment/nginx-deployment nginx=nginx:1.22
kubectl patch deployment nginx-deployment -p '{"spec":{"replicas":2}}'
```

**자동 롤백:**

```yaml
spec:
  progressDeadlineSeconds: 600  # 10분 내 업데이트 완료 필요
  revisionHistoryLimit: 10      # 유지할 ReplicaSet 수
```

## 4. StatefulSets: 상태를 가진 애플리케이션 관리

### 4.1 StatefulSet vs Deployment

| 특성          | Deployment | StatefulSet                              |
|-------------|------------|------------------------------------------|
| **파드 이름**   | 무작위        | 순차적 (web-0, web-1, web-2)                |
| **네트워크 ID** | 임시적        | 안정적 (web-0.service.ns.svc.cluster.local) |
| **스토리지**    | 공유 가능      | 파드별 전용 PVC                               |
| **배포 순서**   | 병렬         | 순차적                                      |
| **업데이트**    | 롤링 (무작위)   | 순차적 (역순)                                 |

### 4.2 StatefulSet 설정

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-cluster
spec:
  serviceName: mysql
  replicas: 3
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
        - name: mysql
          image: mysql:8.0
          env:
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-secret
                  key: root-password
          ports:
            - containerPort: 3306
          volumeMounts:
            - name: mysql-storage
              mountPath: /var/lib/mysql
          readinessProbe:
            exec:
              command:
                - mysqladmin
                - ping
                - -h
                - localhost
            initialDelaySeconds: 30
            periodSeconds: 10
  volumeClaimTemplates:
    - metadata:
        name: mysql-storage
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: fast-ssd
        resources:
          requests:
            storage: 100Gi
---
apiVersion: v1
kind: Service
metadata:
  name: mysql
spec:
  clusterIP: None  # Headless Service
  selector:
    app: mysql
  ports:
    - port: 3306
```

### 4.3 StatefulSet의 고유 기능

**순차적 배포:**

```
mysql-0 → Ready → mysql-1 → Ready → mysql-2
```

**역순 업데이트:**

```
mysql-2 업데이트 → mysql-1 업데이트 → mysql-0 업데이트
```

**안정적 네트워크 식별자:**

```bash
# 각 파드는 예측 가능한 DNS 이름을 가짐
mysql-0.mysql.default.svc.cluster.local
mysql-1.mysql.default.svc.cluster.local
mysql-2.mysql.default.svc.cluster.local
```

## 5. Services: 네트워크 추상화와 서비스 디스커버리

### 5.1 Service 타입별 활용

**ClusterIP (기본값):**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  type: ClusterIP
  selector:
    app: web
  ports:
    - port: 80
      targetPort: 8080
      protocol: TCP
```

**NodePort:**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: web-nodeport
spec:
  type: NodePort
  selector:
    app: web
  ports:
    - port: 80
      targetPort: 8080
      nodePort: 31000  # 30000-32767 범위
```

**LoadBalancer:**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: web-loadbalancer
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: nlb
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
spec:
  type: LoadBalancer
  selector:
    app: web
  ports:
    - port: 80
      targetPort: 8080
```

### 5.2 고급 Service 설정

**Session Affinity:**

```yaml
spec:
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 3600
```

**Multi-Port Services:**

```yaml
spec:
  ports:
    - name: http
      port: 80
      targetPort: 8080
    - name: https
      port: 443
      targetPort: 8443
    - name: metrics
      port: 9090
      targetPort: 9090
```

## 6. Ingress: HTTP/HTTPS 라우팅

### 6.1 Ingress 기본 구성

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-ingress
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  tls:
    - hosts:
        - api.example.com
        - web.example.com
      secretName: example-tls
  rules:
    - host: web.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: web-service
                port:
                  number: 80
    - host: api.example.com
      http:
        paths:
          - path: /v1
            pathType: Prefix
            backend:
              service:
                name: api-v1-service
                port:
                  number: 80
          - path: /v2
            pathType: Prefix
            backend:
              service:
                name: api-v2-service
                port:
                  number: 80
```

### 6.2 Ingress Controller 비교

| Controller        | 특징                 | 적합한 용도          |
|-------------------|--------------------|-----------------|
| **NGINX**         | 가장 널리 사용, 풍부한 기능   | 일반적인 웹 애플리케이션   |
| **Traefik**       | 자동 서비스 디스커버리, 대시보드 | 마이크로서비스, DevOps |
| **HAProxy**       | 고성능, 엔터프라이즈급       | 대용량 트래픽         |
| **Istio Gateway** | 서비스 메시 통합          | 복잡한 마이크로서비스     |

## 7. ConfigMaps & Secrets: 설정과 민감 데이터 관리

### 7.1 ConfigMap 활용 패턴

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  # 키-값 쌍
  database_url: "postgres://db:5432/myapp"
  log_level: "info"
  feature_flags: "feature1=true,feature2=false"

  # 파일 형태
  nginx.conf: |
    server {
        listen 80;
        server_name localhost;

        location / {
            proxy_pass http://backend:8080;
            proxy_set_header Host $host;
        }
    }

  app.properties: |
    spring.datasource.url=jdbc:postgresql://db:5432/myapp
    spring.jpa.hibernate.ddl-auto=validate
    logging.level.org.springframework=INFO
```

### 7.2 Secret 보안 관리

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
type: Opaque
data:
  # Base64로 인코딩된 값
  database-password: cGFzc3dvcmQxMjM=
  api-key: YWJjZGVmZ2hpams=
stringData:
  # 평문으로 입력 (자동으로 Base64 인코딩됨)
  smtp-password: "my-secret-password"
---
apiVersion: v1
kind: Secret
metadata:
  name: docker-registry-secret
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: |
    {
      "auths": {
        "registry.example.com": {
          "username": "user",
          "password": "pass",
          "auth": "dXNlcjpwYXNz"
        }
      }
    }
```

### 7.3 설정 주입 방법

**환경변수로 주입:**

```yaml
spec:
  containers:
    - name: app
      env:
        - name: DATABASE_URL
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: database_url
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: database-password
      envFrom:
        - configMapRef:
            name: app-config
        - secretRef:
            name: app-secrets
```

**볼륨 마운트:**

```yaml
spec:
  containers:
    - name: app
      volumeMounts:
        - name: config-volume
          mountPath: /etc/config
        - name: secret-volume
          mountPath: /etc/secrets
          readOnly: true
  volumes:
    - name: config-volume
      configMap:
        name: app-config
    - name: secret-volume
      secret:
        secretName: app-secrets
        defaultMode: 0400  # 읽기 전용
```

## 8. PersistentVolumeClaims: 영구 스토리지 관리

### 8.1 스토리지 클래스별 PVC

```yaml
# 고성능 SSD 스토리지
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: database-pvc
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 100Gi
---
# 대용량 표준 스토리지
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: logs-pvc
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: standard
  resources:
    requests:
      storage: 1Ti
```

### 8.2 Volume Access Modes

| Mode                    | 설명            | 적합한 용도            |
|-------------------------|---------------|-------------------|
| **ReadWriteOnce (RWO)** | 단일 노드에서 읽기/쓰기 | 데이터베이스, 단일 인스턴스 앱 |
| **ReadOnlyMany (ROX)**  | 여러 노드에서 읽기 전용 | 정적 컨텐츠, 공유 설정     |
| **ReadWriteMany (RWX)** | 여러 노드에서 읽기/쓰기 | 공유 파일 시스템, 로그 수집  |

## 9. Jobs & CronJobs: 배치 작업 관리

### 9.1 Job 설정과 패턴

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: data-migration
spec:
  # 완료할 작업 수
  completions: 5
  # 동시 실행할 파드 수
  parallelism: 2
  # 재시도 횟수
  backoffLimit: 3
  # 작업 완료 후 파드 유지 시간
  ttlSecondsAfterFinished: 3600
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: migrator
          image: migration:latest
          command:
            - /bin/sh
            - -c
            - |
              echo "Starting migration batch ${JOB_COMPLETION_INDEX}"
              # 실제 마이그레이션 로직
              migrate --batch=${JOB_COMPLETION_INDEX}
          env:
            - name: JOB_COMPLETION_INDEX
              valueFrom:
                fieldRef:
                  fieldPath: metadata.annotations['batch.kubernetes.io/job-completion-index']
```

### 9.2 CronJob 스케줄링

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: database-backup
spec:
  # 매일 새벽 2시에 실행
  schedule: "0 2 * * *"
  # 동시 실행 정책
  concurrencyPolicy: Forbid
  # 실패한 작업 보관 수
  failedJobsHistoryLimit: 3
  # 성공한 작업 보관 수
  successfulJobsHistoryLimit: 1
  # 시작 기한 (초)
  startingDeadlineSeconds: 300
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
            - name: backup
              image: postgres:13
              command:
                - /bin/bash
                - -c
                - |
                  BACKUP_FILE="/backup/db_$(date +%Y%m%d_%H%M%S).sql"
                  pg_dump $DATABASE_URL > $BACKUP_FILE

                  # S3에 업로드
                  aws s3 cp $BACKUP_FILE s3://backup-bucket/database/

                  # 로컬 파일 정리
                  rm $BACKUP_FILE
              env:
                - name: DATABASE_URL
                  valueFrom:
                    secretKeyRef:
                      name: db-secret
                      key: url
              volumeMounts:
                - name: backup-storage
                  mountPath: /backup
          volumes:
            - name: backup-storage
              emptyDir: { }
```

## 10. DaemonSets: 노드별 필수 서비스

### 10.1 DaemonSet 활용 사례

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: log-collector
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: log-collector
  template:
    metadata:
      labels:
        name: log-collector
    spec:
      # 시스템 권한 필요
      serviceAccountName: log-collector
      hostNetwork: true
      hostPID: true
      containers:
        - name: fluentd
          image: fluentd:v1.14
          resources:
            limits:
              memory: 512Mi
              cpu: 100m
          volumeMounts:
            # 호스트의 로그 디렉토리 마운트
            - name: varlog
              mountPath: /var/log
              readOnly: true
            - name: containers
              mountPath: /var/lib/docker/containers
              readOnly: true
            # Fluentd 설정
            - name: config
              mountPath: /fluentd/etc
          env:
            - name: ELASTICSEARCH_HOST
              value: "elasticsearch.logging.svc.cluster.local"
            - name: ELASTICSEARCH_PORT
              value: "9200"
      volumes:
        - name: varlog
          hostPath:
            path: /var/log
        - name: containers
          hostPath:
            path: /var/lib/docker/containers
        - name: config
          configMap:
            name: fluentd-config
      # 특정 노드에만 배포 (선택사항)
      nodeSelector:
        node-type: worker
      # 노드 장애 시 빠른 재배포
      tolerations:
        - key: node.kubernetes.io/not-ready
          operator: Exists
          effect: NoExecute
          tolerationSeconds: 30
```
