---
title: "CKA Mock Exam - 1"
date: 2026-01-14
categories: [CKA, Container, Kubernetes]
tags: [CKA, Container, Kubernetes, CRD, Operator, Extensibility]
layout: post
toc: true
math: true
mermaid: true
---

### Q. 1 Multi-container Pod

**Task:** Create a Pod mc-pod in the mc-namespace namespace with three containers. The first container should be named mc-pod-1, run the nginx:1-alpine image, and set an environment variable NODE_NAME to the node name. The second container should be named mc-pod-2, run the busybox:1 image, and continuously log the output of the date command to the file /var/log/shared/date.log every second. The third container should have the name mc-pod-3, run the image busybox:1, and print the contents of the date.log file generated by the second container to stdout. Use a shared, non-persistent volume.

- **공식문서 링크:** 
  - [Configure a Pod to Use a Volume for Storage](https://kubernetes.io/docs/tasks/configure-pod-container/configure-volume-storage/)
  - [Environment variables from fieldRef](https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/#use-pod-fields-as-values-for-environment-variables)
- **검색 키워드:** `emptyDir`, `fieldRef`, `downward api`, `environment variable pod field`

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mc-pod
  namespace: mc-namespace
spec:
  containers:
  - name: mc-pod-1
    image: nginx:1-alpine
    env:
    - name: NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
  - name: mc-pod-2
    image: busybox:1
    command: ["sh", "-c", "while true; do date >> /var/log/shared/date.log; sleep 1; done"]
    volumeMounts:
    - name: shared-volume
      mountPath: /var/log/shared
  - name: mc-pod-3
    image: busybox:1
    command: ["sh", "-c", "tail -f /var/log/shared/date.log"]
    volumeMounts:
    - name: shared-volume
      mountPath: /var/log/shared
  volumes:
  - name: shared-volume
    emptyDir: {}
```

**kubectl explain 활용:**
```bash
kubectl explain pod.spec.containers.env.valueFrom.fieldRef
kubectl explain pod.spec.volumes.emptyDir
```

---

### Q. 2 Install Container Runtime (cri-docker)

**Task:** This question needs to be solved on node node01. To access the node using SSH, use the credentials below:

```shell
username: bob
password: caleston123
```

As an administrator, you need to prepare node01 to install kubernetes. One of the steps is installing a container runtime. Install the cri-docker_0.3.16.3-0.debian.deb package located in /root and ensure that the cri-docker service is running and enabled to start on boot.

- **공식문서 링크:**
  - [Container Runtimes - Docker Engine](https://kubernetes.io/docs/setup/production-environment/container-runtimes/#docker)
- **검색 키워드:** `container runtimes`, `cri dockerd`, `docker engine`

```bash
# node01 SSH 접속
ssh bob@node01
# 패스워드 입력: caleston123

# root 권한 획득
sudo -i

# 패키지 설치
dpkg -i /root/cri-docker_0.3.16.3-0.debian.deb

# 의존성 문제 해결 (있을 경우)
apt-get install -f -y

# systemd 데몬 리로드
systemctl daemon-reload

# cri-docker 서비스와 소켓 활성화 및 시작
systemctl enable cri-docker.service
systemctl enable cri-docker.socket
systemctl start cri-docker.service
systemctl start cri-docker.socket

# 상태 확인
systemctl is-active cri-docker.service
systemctl is-enabled cri-docker.service
systemctl status cri-docker.service
systemctl status cri-docker.socket
```

**주의사항:**
- cri-docker는 `.service`와 `.socket` 두 개의 systemd 유닛이 필요합니다.
- 의존성 문제가 발생할 경우 `apt-get install -f -y` 명령어로 해결합니다.

---

### Q. 3 Identify CRDs

**Task:** On controlplane node, identify all CRDs related to VerticalPodAutoscaler and save their names into the file /root/vpa-crds.txt.

- **공식문서 링크:**
  - [Custom Resources](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/)
  - [Custom Resource Definitions](https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/)
- **검색 키워드:** `kubectl get crd`, `custom resources`, `crd list`

```bash
# 방법 1: grep 사용
kubectl get crd -o custom-columns=NAME:.metadata.name --no-headers | grep verticalpodautoscaler > /root/vpa-crds.txt

# 방법 2: jsonpath 사용
kubectl get crd -o jsonpath='{range .items[?(@.metadata.name=~".*verticalpodautoscaler.*")]}{.metadata.name}{"\n"}{end}' > /root/vpa-crds.txt

# 확인
cat /root/vpa-crds.txt
```

**주의사항:**
- `--no-headers` 옵션을 추가하여 "NAME" 헤더가 파일에 포함되지 않도록 합니다.
- 방법 1이 더 직관적이고 빠르지만, 방법 2는 정규표현식을 활용한 정확한 매칭입니다.

**kubectl explain 활용:**
```bash
kubectl explain crd
kubectl get crd --help
```

---

### Q. 4 Messaging Service

**Task:** Create a service named messaging-service to expose the messaging pod within the cluster on port 6379. The messaging pod is running in the default namespace.

- **공식문서 링크:**
  - [Service](https://kubernetes.io/docs/concepts/services-networking/service/)
  - [kubectl expose](https://kubernetes.io/docs/reference/kubectl/generated/kubectl_expose/)
- **검색 키워드:** `kubectl expose`, `service`, `clusterip`

```bash
# 명령형 커맨드로 서비스 생성
kubectl expose pod messaging --port=6379 --name messaging-service

# 확인
kubectl get svc messaging-service
kubectl describe svc messaging-service
```

**kubectl explain 활용:**
```bash
kubectl explain service.spec
kubectl explain service.spec.ports
```

---

### Q. 5 Create Deployment

**Task:** Create a deployment named hr-web-app using the image kodekloud/webapp-color with 2 replicas.

- **공식문서 링크:**
  - [Deployments](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)
  - [kubectl create deployment](https://kubernetes.io/docs/reference/kubectl/generated/kubectl_create/kubectl_create_deployment/)
- **검색 키워드:** `kubectl create deployment`, `deployment`, `replicas`

```bash
# 명령형 커맨드로 Deployment 생성
kubectl create deployment hr-web-app --image=kodekloud/webapp-color --replicas=2

# 확인
kubectl get deployment hr-web-app
kubectl get pods -l app=hr-web-app
```

**kubectl explain 활용:**
```bash
kubectl explain deployment.spec
kubectl explain deployment.spec.replicas
```

---

### Q. 6 Fix Broken Pod (InitContainer)

**Task:** A new application orange is deployed. There is something wrong with it. Identify and fix the issue.

- **공식문서 링크:**
  - [Init Containers](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/)
- **검색 키워드:** `init containers`, `initContainers`, `pod lifecycle`

```bash
# Pod 정보 확인
kubectl describe pod orange
kubectl logs orange -c init-myservice

# 문제 식별: initContainer에서 "sleeeep" 오타 발견

# YAML 추출 및 수정
kubectl get pod orange -o yaml > orange.yaml

# vi로 sleeeep 2를 sleep 2로 수정
vi orange.yaml

# 또는 sed로 일괄 수정
sed -i 's/sleeeep/sleep/g' orange.yaml

# 기존 Pod 삭제 후 재생성
kubectl replace -f orange.yaml --force

# 확인
kubectl get pod orange
kubectl describe pod orange
```

**kubectl explain 활용:**
```bash
kubectl explain pod.spec.initContainers
kubectl explain pod.spec.initContainers.command
```

---

### Q. 7 Expose Deployment as NodePort

**Task:** Expose the hr-web-app created in the previous task as a service named hr-web-app-service, accessible on port 30082 on the nodes of the cluster. The web application listens on port 8080.

- **공식문서 링크:**
  - [Service - NodePort](https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport)
- **검색 키워드:** `Service NodePort`, `nodePort`, `service types`

```bash
# 방법 1: YAML 생성 후 수정 (권장)
kubectl expose deployment hr-web-app --type=NodePort --port=8080 --name=hr-web-app-service --dry-run=client -o yaml > hr-web-app-service.yaml

# vi로 nodePort 필드 추가
vi hr-web-app-service.yaml
# spec.ports[0] 아래에 추가:
#   nodePort: 30082

# 서비스 생성
kubectl apply -f hr-web-app-service.yaml

# 방법 2: 직접 생성 후 patch (빠르지만 복잡)
kubectl expose deployment hr-web-app --type=NodePort --port=8080 --name=hr-web-app-service
kubectl patch service hr-web-app-service --type='json' -p='[{"op": "replace", "path": "/spec/ports/0/nodePort", "value":30082}]'

# 확인
kubectl get svc hr-web-app-service
kubectl describe svc hr-web-app-service
```

**YAML 예시:**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: hr-web-app-service
spec:
  type: NodePort
  selector:
    app: hr-web-app
  ports:
  - protocol: TCP
    port: 8080
    targetPort: 8080
    nodePort: 30082
```

**kubectl explain 활용:**
```bash
kubectl explain service.spec.type
kubectl explain service.spec.ports.nodePort
```

---

### Q. 8 Persistent Volume

**Task:** Create a Persistent Volume with the given specification:

- Volume name: pv-analytics
- Storage: 100Mi
- Access mode: ReadWriteMany
- Host path: /pv/data-analytics

- **공식문서 링크:**
  - [Persistent Volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)
  - [Volumes - hostPath](https://kubernetes.io/docs/concepts/storage/volumes/#hostpath)
- **검색 키워드:** `PersistentVolume hostPath`, `persistent volume`, `hostPath volume`

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-analytics
spec:
  capacity:
    storage: 100Mi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  hostPath:
    path: /pv/data-analytics
```

**생성 및 확인:**
```bash
# PV 생성
kubectl apply -f pv-analytics.yaml

# 확인
kubectl get pv pv-analytics
kubectl describe pv pv-analytics
```

**kubectl explain 활용:**
```bash
kubectl explain pv.spec
kubectl explain pv.spec.hostPath
kubectl explain pv.spec.accessModes
```

---

### Q. 9 Horizontal Pod Autoscaler (HPA)

**Task:** Create a Horizontal Pod Autoscaler (HPA) with name webapp-hpa for the deployment named kkapp-deploy in the default namespace with the webapp-hpa.yaml file located under the root folder.
Ensure that the HPA scales the deployment based on CPU utilization, maintaining an average CPU usage of 50% across all pods.
Configure the HPA to cautiously scale down pods by setting a stabilization window of 300 seconds to prevent rapid fluctuations in pod count.

Note: The kkapp-deploy deployment is created for backend; you can check in the terminal.

- **공식문서 링크:**
  - [Horizontal Pod Autoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
  - [HPA Configurable Scaling Behavior](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#configurable-scaling-behavior)
- **검색 키워드:** `stabilizationWindowSeconds`, `horizontal pod autoscaler`, `hpa behavior`, `scale down`

```bash
# 먼저 기존 deployment의 replicas 확인
kubectl get deployment kkapp-deploy -o jsonpath='{.spec.replicas}'
```

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: webapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kkapp-deploy
  minReplicas: 1  # Task에 명시 안됨. 기존 deployment replicas 또는 1 사용
  maxReplicas: 10  # Task에 명시 안됨. 일반적으로 10 사용
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
```

**생성 및 확인:**
```bash
# HPA 생성
kubectl apply -f webapp-hpa.yaml

# 확인
kubectl get hpa webapp-hpa
kubectl describe hpa webapp-hpa
```

**kubectl explain 활용:**
```bash
kubectl explain hpa.spec
kubectl explain hpa.spec.behavior
kubectl explain hpa.spec.behavior.scaleDown
```

---

### Q. 10 Vertical Pod Autoscaler (VPA)

**Task:** Deploy a Vertical Pod Autoscaler (VPA) with name analytics-vpa for the deployment named analytics-deployment in the default namespace.
The VPA should automatically adjust the CPU and memory requests of the pods to optimize resource utilization. Ensure that the VPA operates in Recreate mode, allowing it to evict and recreate pods with updated resource requests as needed.

- **공식문서 링크:**
  - [Vertical Pod Autoscaler (GitHub)](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler)
- **검색 키워드:** `VerticalPodAutoscaler`, `vpa`, `vertical pod autoscaler`

```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: analytics-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: analytics-deployment
  updatePolicy:
    updateMode: "Recreate"
```

**생성 및 확인:**
```bash
# VPA 생성
kubectl apply -f analytics-vpa.yaml

# 확인
kubectl get vpa analytics-vpa
kubectl describe vpa analytics-vpa
```

**kubectl explain 활용**
```bash
kubectl explain vpa
kubectl explain vpa.spec
kubectl explain vpa.spec.targetRef
kubectl explain vpa.spec.updatePolicy
```

---

### Q. 11 Kubernetes Gateway

**Task:** Create a Kubernetes Gateway resource with the following specifications:

- Name: web-gateway
- Namespace: nginx-gateway
- Gateway Class Name: nginx
- Listeners:
  - Protocol: HTTP
  - Port: 80
  - Name: http

- **공식문서 링크:**
  - [Gateway API](https://kubernetes.io/docs/concepts/services-networking/gateway/)
  - [Gateway API (SIG Network)](https://gateway-api.sigs.k8s.io/api-types/gateway/)
- **검색 키워드:** `Gateway API spec`, `gateway api`, `gateway listeners`

```bash
# 먼저 클러스터에 설치된 Gateway API 버전 확인
kubectl api-resources | grep gateway

# 또는 CRD로 확인
kubectl get crd gateways.gateway.networking.k8s.io -o yaml | grep "storage: true" -B 2

# kubectl explain으로 확인
kubectl explain gateway
```

```yaml
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: web-gateway
  namespace: nginx-gateway
spec:
  gatewayClassName: nginx
  listeners:
    - name: http
      protocol: HTTP
      port: 80
```

**생성 및 확인:**
```bash
# Gateway 생성
kubectl apply -f web-gateway.yaml

# 확인
kubectl get gateway -n nginx-gateway
kubectl describe gateway web-gateway -n nginx-gateway
```

**kubectl explain 활용**
```bash
kubectl explain gateway
kubectl explain gateway.spec
kubectl explain gateway.spec.listeners
```

---

### Q. 12 Helm Repo and Upgrade

**Task:** One co-worker deployed an nginx helm chart kk-mock1 in the kk-ns namespace on the cluster. A new update is pushed to the helm chart, and the team wants you to update the helm repository to fetch the new changes.

After updating the helm chart, upgrade the helm chart version to 18.1.15.

- **공식문서 링크:**
  - [Helm Upgrade](https://helm.sh/docs/helm/helm_upgrade/)
  - [Helm Repo Update](https://helm.sh/docs/helm/helm_repo_update/)
  - [Helm Search Repo](https://helm.sh/docs/helm/helm_search_repo/)
- **검색 키워드:** `helm upgrade`, `helm repo update`, `helm search`, `helm list`

```bash
# 현재 설치된 릴리스 확인
helm list -n kk-ns

# 리포지토리 목록 확인
helm repo list

# 리포지토리 업데이트
helm repo update

# 사용 가능한 차트 버전 확인
helm search repo kk-mock1/nginx --versions

# 차트 업그레이드 (버전 18.1.15로)
helm upgrade kk-mock1 kk-mock1/nginx -n kk-ns --version 18.1.15

# 업그레이드 결과 확인
helm list -n kk-ns
helm history kk-mock1 -n kk-ns

# Pod 상태 확인
kubectl get pods -n kk-ns
```

**추가 Helm 명령어:**
```bash
# 현재 릴리스의 values 확인
helm get values kk-mock1 -n kk-ns

# 차트의 기본 values 확인
helm show values kk-mock1/nginx

# 특정 버전의 차트 정보 확인
helm show chart kk-mock1/nginx --version 18.1.15
```

---

## 문제 풀이 팁

### kubectl explain 활용법
```bash
# 리소스의 전체 구조 확인
kubectl explain <resource>

# 특정 필드의 상세 정보 확인
kubectl explain <resource>.spec
kubectl explain <resource>.spec.field

# 재귀적으로 모든 필드 확인
kubectl explain <resource> --recursive

# 예시
kubectl explain pod.spec.containers.env
kubectl explain service.spec.type
kubectl explain deployment.spec.replicas
```

### 공식문서 검색 전략
1. **Kubernetes 공식 문서:** https://kubernetes.io/docs/
2. **kubectl 치트시트:** https://kubernetes.io/docs/reference/kubectl/cheatsheet/
3. **API Reference:** https://kubernetes.io/docs/reference/kubernetes-api/
4. **시험 중 검색 키워드:**
  - `kubectl <resource>` (예: `kubectl deployment`)
  - `kubernetes <개념>` (예: `kubernetes service`)
  - `<resource> example` (예: `pod example`)

### 시험 시 주의사항
1. **항상 namespace 확인:** `-n` 옵션 사용
2. **dry-run 활용:** `--dry-run=client -o yaml`로 템플릿 생성
3. **kubectl explain 활용:** 필드명이나 구조가 불확실할 때
4. **리소스 확인:** `kubectl get`, `kubectl describe`로 검증
5. **공식문서 즐겨찾기:** 시험 시작 전 주요 페이지 북마크
